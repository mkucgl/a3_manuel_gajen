<!DOCTYPE html><html><head><title>Programming Assignment 3</title><meta charse="UTF-8" />
<style type="text/css">
pre, code { background-color: #DEDEDE; white-space: pre-wrap; word-break: break-all; }
pre { padding: 0.5rem; border: 1px solid #CCCCCC;  }
a, a:hover, a:active, a:focus { color: blue; }
</style>
</head><body>
<h1 id="programming-assignment-3">Programming Assignment 3</h1>
<p>Handed in by Manuel Kunz and Gajendira Sivajothi</p>
<h2 id="introduction">Introduction</h2>
<p>The code we produced to solve the programming assignment can be found in the file
&quot;assignment3.py&quot;. We created a single classifier that can be used for both types of data
(the path to a list of institution or place of birth specific lemmas can be specified via
the command line arguments described just below). This one program can perform the
training (action <code>lrtrain</code>), the testing/classification (action <code>lrclassify</code>) and the
10-fold cross-validation (action <code>lrvalidate</code>).</p>
<p>Note: After the program has trained (after an invocation with the action <code>lrtrain</code>), it
stores the trained classifier for later use with the action <code>lrclassify</code>.</p>
<p>This is how you call the program (examples below):</p>
<pre><code>python3 assignment3.py &lt;action: lrtrain|lrclassify|lrvalidate&gt; &lt;path to corpus&gt; &lt;path to lemmas list&gt;[ &lt;Google API Key&gt;]
</code></pre><p>It expects the following command line arguments:</p>
<ol>
<li><p>The action the script should perform. This must be one of:</p>
<ul>
<li><code>lrtrain</code>: tains the Logistic Regression model; learns the weights from the
specified training corpus; (&quot;lr&quot; stands for Logistic Regression)</li>
<li><code>rclassify</code>: uses the learned weights to classify the items of the specified test
corpus items (using the trained Logistic Regression model stored during the
execution of the <code>lrtrain</code> action).</li>
<li><code>lrvalidate</code>: performs a 10 fold cross validation</li>
</ul>
</li>
<li>The path to the corpus file (e.g. &quot;institution_test.json&quot;)</li>
<li>The path to the file containing the argument lists from which features are constructed
(e.g. &quot;institution_args.json&quot; or &quot;place-of-birth_args.json&quot;)</li>
<li>The Google API Key; This argument can be ommitted if all entities are already in the
cache (which is the case for all institution and the place of birth data set versions)</li>
</ol>
<p>Example 1 (only training; use your own API key if new features need to be downloaded,
otherwise you can omit the API key):</p>
<pre><code>python3 assignment3.py lrtrain institution_train.json institution_args.json G00gleAPIk3y
</code></pre><p>Example 2 (training, then testing/classification):</p>
<pre><code>python3 assignment3.py lrtrain institution_train.json institution_args.json
python3 assignment3.py lrclassify institution_test.json institution_args.json
</code></pre><p>Example 3 (10-fold cross validation):</p>
<pre><code>python3 assignment3.py lrvalidate place-of-birth_nodev.json place-of-birth_args.json
</code></pre><h2 id="documentation-of-development">Documentation of Development</h2>
<p>In this section we describe the development process that lead to the solution we handed
in. The actual code can be found in the file &quot;assignment3&quot;. It is well structured into
functions and all functions are extensively commented. In order to keep a clean structure
for this report we did not copy/paste the code sections into the report. Instead we
reference the relevant function names and the reader can look up the implementation
details in the code.</p>
<h3 id="exercise-1-and-general-preparation">Exercise 1 and General Preparation</h3>
<ol>
<li>After reading the entire exercise sheet we created the file &quot;assignment3.py&quot; for our
solution. We decided to create a single program that can classify both types of
relations. An empty <code>main</code> function was created.</li>
<li>We downloaded the files &quot;20130403-institution.json&quot; and
&quot;20130403-place-of-birth.json&quot;</li>
<li>We inspected the instructions/examples on how to resolve IDs (ResolvingIDs.docx). We
assessed the requirements for using ID resolution and created a Google account for
our team and an API key for this account.</li>
<li><p>We created the file &quot;IMD_resolver.py&quot; which initially contained the exact code found
in &quot;ResolvingIDs.docx&quot; and included it in &quot;assignment3.py&quot;. We added all the
necessary <code>import</code>s in both files and tries to resolve some first IDs. After this
worked made a small change to &quot;IMD_resolver.py&quot; so that it returnes the entire data
retrieved from Google (and not just the entity name) so that we could later store all
the information locally (because we had heard that downloading all the entities takes
a long time and we did not want to risk doing it twice).</p>
<p>Now we were able to resolve IDs (without local cache).</p>
</li>
<li><p>Since downloading all the entity data really takes a long time, we then implemented
local caching. When new entities are downloaded, they are added to a dictionary
during runtime (in code <code>entity_cache</code>). After programm execution the script should
store all entity data it knows in a local file (file: &quot;entity_cache.json&quot;, see
function: <code>store_entity_cache</code>). When the program starts it should load all the
entity data gathered in earlier executions (function: <code>load_entity_cache</code>).</p>
<p>For convenient use we wrote the function <code>get_entity_name</code> which gets the entity name
from the <code>entity_cache</code> if possible and defaults to downloading the entity data if
necessary.</p>
</li>
<li>We put the code for processing a data set file line-by-line into &quot;assignment3.py&quot;,
parsed the json for each line (reacted to illegal backslashes) and called
<code>get_entity_name</code> on all subject/object IDs. This way we built up our cache with all
the necessary entity data (which took a whole night to execute because this one time
all the data had to be downloaded from Google).</li>
<li>Next we addressed the problem of aggregating the raters&#39; judgments into a single
judgment (multiple yes/no into a single yes/no): the target/gold class. We chose to
treat an item positively (relation present) if a certain percentage of raters said
yes (default 50%). For this we implemented the function <code>is_positive_item</code>.</li>
<li>Next we tackled the problem of finding the entity names in the snippet. After looking
at some of the entity names and the respective snippets (<code>print</code>), we chose to go
with a regular expression approach to finding the entity names. This is implemented
in the function <code>find_entity_in_snippet</code> which has a comment explaining how it works
in detail.</li>
<li><p>Then we split the corpora/data sets (development/training/test). The exact way the
sets were split is described below (see section <a href="#data-sets">Data Sets</a> below).</p>
<p>The &quot;_nodev&quot; data sets (also described in <a href="#data-sets">Data Sets</a> below) containing
all but the development data on which the 10-fold cross-validation could be run were
created only later during the implementation of the 10-fold cross validation (see
below).</p>
</li>
</ol>
<h3 id="exercise-2">Exercise 2</h3>
<ol>
<li>We created the function <code>collect_features</code> for extracting features.</li>
<li>We inserted two very simple features: <code>subject_match_count</code> and <code>object_match_count</code>
(features are described below) to have some features to work with during development.</li>
<li><p>At this point we did not yet know how the Logistic Regression had to be performed
(What has to be <code>import</code>ed/installed? What arguments will the package expect? What
results will it produce?).</p>
<ul>
<li>We did not know how much time it would take to implement the use of the Logistic
Regression.</li>
<li>We wanted to know in which format the features had to be represented.</li>
<li>We wanted to see what result the features ultimately produce.</li>
</ul>
<p>Therefore, instead of adding more features right away, we continued with the
implementation of the code for the call to the Logistic Regression (described below
in the next section <a href="#exercise-3">Exercise 3</a>).</p>
</li>
<li>Since we wanted to use some lemmas as features (occurrence indicators), we tried to
produce a lemma list automatically with sklearn&#39;s <code>SelectKBest</code> from the development
data sets. For this the function <code>get_k_best_lemmas</code> was implemented. The result were
the JSON list files &quot;institution_args.json&quot; and &quot;place-of-birth_args.json&quot;. We
implemented the functionality of accepting a list file as command line parameter
(in <code>main</code> and in <code>get_feature_matrix_and_target_classes_for_corpus_file</code>) and
derived the feature values in <code>collect_features</code>.</li>
<li>Since we have started using spaCy and noticed that it takes a lot of time parsing
each snippet (<code>nlp(snippet)</code> for thousands of snippets), we implemented a mechanism
that stores the spaCy parses between executions of the program and loads them again
(<code>pickle.load(open(snippet_docs_pickle_path, &#39;rb&#39;))</code>,
<code>pickle.dump(snippet_docs, open(snippet_docs_pickle_path, &#39;wb&#39;))</code>) for the first
3000 items. This way a lot of waiting could be avoided.</li>
<li>Finally we added features until the time for this programming assignment was up. All
the features are described below and in the function <code>collect_features</code>.</li>
</ol>
<h3 id="exercise-3">Exercise 3</h3>
<ol>
<li>We researched sklearn&#39;s <code>LogisticRegression</code> and made a simple test with dummy data
with the <code>feature_matrix</code> initially containing only two columns (see above). The
<code>fit</code> and <code>predict</code> methods worked and we were able to retrieve the coefficients 
(weights) we expected from the lecture.</li>
<li>Our program was structured to have separate training (<code>lrtrain</code>) and testing
(<code>lrclassify</code>) actions which which would be run individually/consecutively. To make
this work we had to store the trained weights between executions. There seems to be
no way of creating a <code>LogisticRegression</code> object only from weights. We therefore
stored the entire object using <code>pickle</code> (see functions
<code>store_logistic_regression_object</code> and <code>load_logistic_regression_object</code>). This works
very well.</li>
<li>We collected the first evaluation data (initially only system and baseline accuracy).
We chose the following <a href="#baseline">baseline</a>: The baseline performance is the highest
performance achievable assigning the same class to all the items (assigning the class
that is more frequent in the data set). We printed this initial evaluation data and
were &quot;shocked&quot; to see that with the initial 2 features our classifier exactly follows
the baseline strategy. Of course this changed when we started adding more features
but until the end our classifier had a tendency of classifying too many items as
positive (see also <a href="#error-analysis">Error Analysis</a>).</li>
<li>We implemented the 10-fold cross-validation using sklearn&#39;s <code>KFold</code> (see <code>main</code>
function under action <code>lrvalidate</code> in &quot;assignment3.py&quot;). As mentioned above, we
created the &quot;_nodev&quot; data sets (described below) for running the 10-fold
cross-validation on.</li>
<li>We refined our evaluation code especially to also include a confusion matrix and
average performance data over the folds (used for the <code>lrclassify</code> and the
<code>lrvalidate</code> actions). The function where you can find the details is
<code>print_evaluation</code>. To see the results you can run the program or look at the results
provided in <a href="#appendix-1-results">Appendix 1: Results</a>.</li>
</ol>
<h3 id="exercise-4">Exercise 4</h3>
<ol>
<li>In the very end we wrote this report.</li>
</ol>
<h3 id="exercise-5">Exercise 5</h3>
<ol>
<li>Looking forward to the presentation next Tuesday.</li>
</ol>
<h2 id="decisions">Decisions</h2>
<h3 id="data-sets">Data Sets</h3>
<p>Each of the downloaded corpora we split into three parts:</p>
<ul>
<li>Development data set (5% of the lines): Used for inspection during development /
feature design. Files containing these data sets are suffixed with &quot;_dev&quot;.</li>
<li>Training data set (75% of the lines): Used for training the Logistic Regression
classifier. Files containing these data sets are suffixed with &quot;_train&quot;.</li>
<li>Test data set (20% of the lines): Used for testing the Logistic Regression classifier
trained with the training set. Files containing these data sets are suffixed with
&quot;_test&quot;.</li>
</ul>
<p>For the development data set for example we took the top most 5% of the lines. The
following 75% of the lines were assigned to the training set. The last 20% make up the
test set.</p>
<p>In addition we created files that contain all the lines except for those used in the
development data sets. These have the name suffix &quot;_nodev&quot;. They were used to run the
10-fold cross-validation (action <code>lrvalidate</code>). This is how the results at the end of the
report were created.</p>
<h3 id="aggregation-of-judgments">Aggregation of Judgments</h3>
<p>We chose to treat an item as positive (relation present) if at least 50% of the raters
said &quot;yes&quot; to it.</p>
<h3 id="baseline">Baseline</h3>
<p>As a baseline we chose the strategy of only assigning one class. The baseline performance
is the best performance that could be achieved using this strategy (always assigning the
class that occurs more often in the data).</p>
<h3 id="features">Features</h3>
<p>The code for extracting the features can be found in the function <code>collect_features</code>.</p>
<h4 id="subject-object-name-in-snippet">Subject / Object Name in Snippet</h4>
<p>The intuition behind these features is to allow the classifier to figure out whether the
entities identified by the IDs really are mentioned in the snippet (and not for example
some other person with the same name or some other city in a different state / country).</p>
<ul>
<li><code>subject_match_count</code>: Number of <code>subject_name_matches</code> (occurrences of the subject
entity name in snippet found by the function <code>find_entity_in_snippet</code>)</li>
<li><code>object_match_count</code>: Number of <code>object_name_matches</code> (occurrences of the object
entity name in snippet found by the function <code>find_entity_in_snippet</code>)</li>
<li><code>exact_subject_name_match_indicator</code>: Indicates (1: yes, 0: no) whether the exact
subject name retrieved from Google was found in the snippet</li>
<li><code>exact_object_name_match_indicator</code>: Indicates (1: yes, 0: no) whether the exact object
name retrieved from Google was found in the snippet</li>
<li><code>object_comma_appended_place_in_snippet</code>: Indicates (1: yes, 0: no) whether the upper
case part of the object name after the comma (that often is a country or state name) is
found in the snippet</li>
<li><code>&lt;all|first&gt;_subject_name_parts_in_snippet</code>: Indicates (1: yes, 0: no) whether the
first|all (non-1-length, whitespace or punctuation separated) parts of
the subject name are found in the snippet</li>
<li><code>all_object_name_parts_in_snippet</code>: Indicates (1: yes, 0: no) whether all
(non-1-length, whitespace or punctuation separated) parts of the object name are found
in the snippet</li>
<li><code>all_upper_case_object_name_parts_in_snippet</code>: Indicates (1: yes, 0: no) whether all
(non-1-length, whitespace or punctuation separated) upper case parts of the object
name are found in the snippet</li>
</ul>
<h4 id="lemmas">Lemmas</h4>
<p>These features are constructed from the lemma list read from the file provided as third
command line parameter. The intuition is that the words used in the snippets give a clue
whether they describe the relationship in question. Whether or not a specific lemma
occurs in the snippet might therefor help the classifier make its judgment. Playing
around with the code these features have proven to have a great effect on the accuracy
of the classifier.</p>
<ul>
<li><code>lemma_list_count_&lt;lemma&gt;</code>: The number of occurrences of the lemmas in the current
lemma list in the snippet (normalized by the total number of lemmas).</li>
<li><code>lemma_list_indicator_&lt;lemma&gt;</code>: Indicators for occurrence of the lemmas in the list in
the snippet</li>
</ul>
<h4 id="spacy-named-entities">SpaCy Named Entities</h4>
<p>These features try to provide some of the named entity information provided by SpaCy to
the classifier.</p>
<ul>
<li><code>ner_entity_type_count_&lt;entity_type&gt;</code>: Number of times the entity type occurs in
snippet</li>
<li><code>ner_entity_type_indicator_&lt;entity_type&gt;</code>: Indicators whether entity type occurs in
snippet</li>
<li><code>subject_as_ne</code>: Value that indicates (1: yes, 0: no) whether a named entity was found
by spaCy overlapping a subject name match.</li>
<li><code>subject_as_entity_type_&lt;entity_type&gt;_indicator</code>: Value that indicates whether a
subject name match intersects a named entity token of type <code>&lt;entity_type&gt;</code> identified
by spaCy. 1 if spaCy found a named entity of type <code>&lt;entity_type&gt;</code> intersecting a
subject name match, 0 otherwise.</li>
<li><code>subject_as_entity_type_&lt;entity_type&gt;_count</code>: Number of spaCy tokens of named entity
type <code>&lt;entity_type&gt;</code> overlapping a subject name match.</li>
<li><code>subject_as_entity_type_&lt;entity_type&gt;_share</code>: The percentage of all named entity tokens
found by spaCy overlapping a subject name match that are of type <code>&lt;entity_type&gt;</code>.</li>
<li><code>object_as_ne</code>: Value that indicates (1: yes, 0: no) whether a named entity was found
by spaCy overlapping a object name match.</li>
<li><code>object_as_entity_type_&lt;entity_type&gt;_indicator</code>: Value that indicates whether an object
name match intersects a named entity token of type <code>&lt;entity_type&gt;</code> identified by spaCy.
1 if spaCy found a named entity of type <code>&lt;entity_type&gt;</code> intersecting an object name
match, 0 otherwise.</li>
<li><code>object_as_entity_type_&lt;entity_type&gt;_count</code>: Number of spaCy tokens of named entity
type <code>&lt;entity_type&gt;</code> overlapping an object name match.</li>
<li><code>object_as_entity_type_&lt;entity_type&gt;_share</code>: The percentage of all named entity tokens
found by spaCy overlapping an object name match that are of type <code>&lt;entity_type&gt;</code>.</li>
</ul>
<h4 id="personal-pronouns">Personal Pronouns</h4>
<p>Since they are so common we thought they might bear some information.</p>
<ul>
<li><code>he_indicator</code>: Value (1: yes, 0: no) indicating whether the snippet contains the
personal pronoun &quot;he&quot;.</li>
<li><code>she_indicator</code>: Value (1: yes, 0: no) indicating whether the snippet contains the
personal pronoun &quot;she&quot;.</li>
</ul>
<h4 id="sentence-structure-and-dependency-tree">Sentence Structure and Dependency Tree</h4>
<p>We thought the properties of the sentences and the position of the subject/object
tokens/matches therein might give a hint at the content. The dependency tree was
mentioned in articles as possible feature.</p>
<ul>
<li><code>subject_name_in_first_sentence</code>: Indicates (1: yes, 0: no) whether the subject name
occurred in the first sentence</li>
<li><code>object_name_in_first_sentence</code>: Indicates (1: yes, 0: no) whether the object name
occurred in the first sentence</li>
<li><code>first_sentence_with_subject</code>: Index of the first sentence in which the subject name
was found</li>
<li><code>first_sentence_with_object</code>: Index of the first sentence in which the object name was
found</li>
<li><code>subject_and_object_in_same_sentence</code>: Indicates (1: yes, 0: no) whether the subject
and object name have ever been found in the same sentence</li>
<li><code>avg_sentence_length</code>: The average sentence length measured in spaCy tokens.</li>
<li><code>&lt;shortest|longest|first&gt;_sentence_length</code>: Length of the shortest| longest|first
sentence measured in spaCy tokens</li>
<li><code>sentence_counter</code>: The number of sentences in the snippet</li>
<li><code>subject_object_min_distance</code>: Minimum number of tokens between occurrences</li>
<li><code>subj_dep_indicator_&lt;relation_type&gt;</code>: Indicates (1: yes, 0: no) whether a subject token
ever occurs in a (spaCy) dependency relation of type <code>&lt;relation_type&gt;</code> to its head.</li>
<li><code>obj_dep_indicator_&lt;relation_type&gt;</code>: Indicates (1: yes, 0: no) whether a object token
ever occurs in a (spaCy) dependency relation of type <code>&lt;relation_type&gt;</code> to its head.</li>
<li><code>&lt;min|max&gt;_&lt;subj|obj&gt;_root_path_len</code>: Minimal|maximal length of the path from a
subject|object token to the root of the spaCy dependency tree it belongs to</li>
</ul>
<h2 id="error-analysis">Error Analysis</h2>
<p>Most of the errors the classifier makes at the moment are false positives (it classifies
the snippet as containing the relation even though the rater&#39;s majority said &quot;no&quot;).</p>
<p>Even for us as humans it is often not easy to understand why some snippets are judged
negatively. Many of them contain the wrong person or contain slightly ambiguous
statements (e.g. saying that someone was born <em>near</em> a place or received a degree from
some institution but then continued their carrer at an other institution or in an other
field). Concentrating more on trying to identify whether the right
person/place/institution features in the snippet seems a good strategy for further
development of the classifier (as opposed to trying to identify whether the snippet
contains the relation for some subject/object pair, not necessarily those with the Google
API IDs from the data).</p>
<p>The lemma lists turned out to have a large effect on accuracy. We realized that
additional features can even decrease accuracy (overfitting?). That in mind the
classifier could maybe improved in a future development effort by fiddling around more
with these lemma lists (especially dropping some of the more suspicious lemmas).</p>
<p>Finally we realized that, as suggested in the exercise, the percentage of raters needed
to treat an item as positive (target/gold class) has a large effect on the performance
of the classifier.</p>
<h2 id="appendix-1-results">Appendix 1: Results</h2>
<pre><code>$ python3 assignment3.py lrvalidate institution_nodev.json institution_args.json
Processing item 000000 (preparation and feature extraction)
Processing item 000001 (preparation and feature extraction)
Processing item 000002 (preparation and feature extraction)
...
Processing item 040494 (preparation and feature extraction)
Processing item 040495 (preparation and feature extraction)
Processing item 040496 (preparation and feature extraction)

Fold  1 / 10
------------

                  +-----------------+-----------------+-----------------+
                  | Target positive | Target negative | SUM             |
+-----------------+-----------------+-----------------+-----------------+
| System positive |    2047  65.46% |     600  19.19% |    2647  84.65% |
+-----------------+-----------------+-----------------+-----------------+
| System negative |     148   4.73% |     332  10.62% |     480  15.35% |
+-----------------+-----------------+-----------------+-----------------+
| SUM             |    2195  70.20% |     932  29.80% |    3127         |
+-----------------+-----------------+-----------------+-----------------+

Baseline: 70.20%
System accuracy: 76.08%

Fold  2 / 10
------------

                  +-----------------+-----------------+-----------------+
                  | Target positive | Target negative | SUM             |
+-----------------+-----------------+-----------------+-----------------+
| System positive |    2040  65.24% |     614  19.64% |    2654  84.87% |
+-----------------+-----------------+-----------------+-----------------+
| System negative |     146   4.67% |     327  10.46% |     473  15.13% |
+-----------------+-----------------+-----------------+-----------------+
| SUM             |    2186  69.91% |     941  30.09% |    3127         |
+-----------------+-----------------+-----------------+-----------------+

Baseline: 69.91%
System accuracy: 75.70%

Fold  3 / 10
------------

                  +-----------------+-----------------+-----------------+
                  | Target positive | Target negative | SUM             |
+-----------------+-----------------+-----------------+-----------------+
| System positive |    2062  65.94% |     577  18.45% |    2639  84.39% |
+-----------------+-----------------+-----------------+-----------------+
| System negative |     161   5.15% |     327  10.46% |     488  15.61% |
+-----------------+-----------------+-----------------+-----------------+
| SUM             |    2223  71.09% |     904  28.91% |    3127         |
+-----------------+-----------------+-----------------+-----------------+

Baseline: 71.09%
System accuracy: 76.40%

Fold  4 / 10
------------

                  +-----------------+-----------------+-----------------+
                  | Target positive | Target negative | SUM             |
+-----------------+-----------------+-----------------+-----------------+
| System positive |    2068  66.13% |     606  19.38% |    2674  85.51% |
+-----------------+-----------------+-----------------+-----------------+
| System negative |     157   5.02% |     296   9.47% |     453  14.49% |
+-----------------+-----------------+-----------------+-----------------+
| SUM             |    2225  71.15% |     902  28.85% |    3127         |
+-----------------+-----------------+-----------------+-----------------+

Baseline: 71.15%
System accuracy: 75.60%

Fold  5 / 10
------------

                  +-----------------+-----------------+-----------------+
                  | Target positive | Target negative | SUM             |
+-----------------+-----------------+-----------------+-----------------+
| System positive |    2087  66.74% |     567  18.13% |    2654  84.87% |
+-----------------+-----------------+-----------------+-----------------+
| System negative |     152   4.86% |     321  10.27% |     473  15.13% |
+-----------------+-----------------+-----------------+-----------------+
| SUM             |    2239  71.60% |     888  28.40% |    3127         |
+-----------------+-----------------+-----------------+-----------------+

Baseline: 71.60%
System accuracy: 77.01%

Fold  6 / 10
------------

                  +-----------------+-----------------+-----------------+
                  | Target positive | Target negative | SUM             |
+-----------------+-----------------+-----------------+-----------------+
| System positive |    2033  65.01% |     605  19.35% |    2638  84.36% |
+-----------------+-----------------+-----------------+-----------------+
| System negative |     142   4.54% |     347  11.10% |     489  15.64% |
+-----------------+-----------------+-----------------+-----------------+
| SUM             |    2175  69.56% |     952  30.44% |    3127         |
+-----------------+-----------------+-----------------+-----------------+

Baseline: 69.56%
System accuracy: 76.11%

Fold  7 / 10
------------

                  +-----------------+-----------------+-----------------+
                  | Target positive | Target negative | SUM             |
+-----------------+-----------------+-----------------+-----------------+
| System positive |    2083  66.63% |     564  18.04% |    2647  84.68% |
+-----------------+-----------------+-----------------+-----------------+
| System negative |     155   4.96% |     324  10.36% |     479  15.32% |
+-----------------+-----------------+-----------------+-----------------+
| SUM             |    2238  71.59% |     888  28.41% |    3126         |
+-----------------+-----------------+-----------------+-----------------+

Baseline: 71.59%
System accuracy: 77.00%

Fold  8 / 10
------------

                  +-----------------+-----------------+-----------------+
                  | Target positive | Target negative | SUM             |
+-----------------+-----------------+-----------------+-----------------+
| System positive |    2058  65.83% |     616  19.71% |    2674  85.54% |
+-----------------+-----------------+-----------------+-----------------+
| System negative |     158   5.05% |     294   9.40% |     452  14.46% |
+-----------------+-----------------+-----------------+-----------------+
| SUM             |    2216  70.89% |     910  29.11% |    3126         |
+-----------------+-----------------+-----------------+-----------------+

Baseline: 70.89%
System accuracy: 75.24%

Fold  9 / 10
------------

                  +-----------------+-----------------+-----------------+
                  | Target positive | Target negative | SUM             |
+-----------------+-----------------+-----------------+-----------------+
| System positive |    2043  65.36% |     611  19.55% |    2654  84.90% |
+-----------------+-----------------+-----------------+-----------------+
| System negative |     170   5.44% |     302   9.66% |     472  15.10% |
+-----------------+-----------------+-----------------+-----------------+
| SUM             |    2213  70.79% |     913  29.21% |    3126         |
+-----------------+-----------------+-----------------+-----------------+

Baseline: 70.79%
System accuracy: 75.02%

Fold 10 / 10
------------

                  +-----------------+-----------------+-----------------+
                  | Target positive | Target negative | SUM             |
+-----------------+-----------------+-----------------+-----------------+
| System positive |    1990  63.66% |     649  20.76% |    2639  84.42% |
+-----------------+-----------------+-----------------+-----------------+
| System negative |     157   5.02% |     330  10.56% |     487  15.58% |
+-----------------+-----------------+-----------------+-----------------+
| SUM             |    2147  68.68% |     979  31.32% |    3126         |
+-----------------+-----------------+-----------------+-----------------+

Baseline: 68.68%
System accuracy: 74.22%

Summary
-------

+---------------------------+---------+----------+
| System better             |      10 |  100.00% |
+---------------------------+---------+----------+
| Baseline better           |       0 |    0.00% |
+---------------------------+---------+----------+
| Average accuracy baseline |             70.55% |
+---------------------------+--------------------+
| Average accuracy system   |             75.84% |
+---------------------------+--------------------+


$ python3 assignment3.py lrvalidate place-of-birth_nodev.json place-of-birth_args.json
Processing item 000000 (preparation and feature extraction)
Processing item 000001 (preparation and feature extraction)
Processing item 000002 (preparation and feature extraction)
...
Processing item 009086 (preparation and feature extraction)
Processing item 009087 (preparation and feature extraction)
Processing item 009088 (preparation and feature extraction)

Fold  1 / 10
------------

                  +-----------------+-----------------+-----------------+
                  | Target positive | Target negative | SUM             |
+-----------------+-----------------+-----------------+-----------------+
| System positive |     578  69.81% |     127  15.34% |     705  85.14% |
+-----------------+-----------------+-----------------+-----------------+
| System negative |      33   3.99% |      90  10.87% |     123  14.86% |
+-----------------+-----------------+-----------------+-----------------+
| SUM             |     611  73.79% |     217  26.21% |     828         |
+-----------------+-----------------+-----------------+-----------------+

Baseline: 73.79%
System accuracy: 80.68%

Fold  2 / 10
------------

                  +-----------------+-----------------+-----------------+
                  | Target positive | Target negative | SUM             |
+-----------------+-----------------+-----------------+-----------------+
| System positive |     568  68.60% |     128  15.46% |     696  84.06% |
+-----------------+-----------------+-----------------+-----------------+
| System negative |      42   5.07% |      90  10.87% |     132  15.94% |
+-----------------+-----------------+-----------------+-----------------+
| SUM             |     610  73.67% |     218  26.33% |     828         |
+-----------------+-----------------+-----------------+-----------------+

Baseline: 73.67%
System accuracy: 79.47%

Fold  3 / 10
------------

                  +-----------------+-----------------+-----------------+
                  | Target positive | Target negative | SUM             |
+-----------------+-----------------+-----------------+-----------------+
| System positive |     577  69.69% |     109  13.16% |     686  82.85% |
+-----------------+-----------------+-----------------+-----------------+
| System negative |      46   5.56% |      96  11.59% |     142  17.15% |
+-----------------+-----------------+-----------------+-----------------+
| SUM             |     623  75.24% |     205  24.76% |     828         |
+-----------------+-----------------+-----------------+-----------------+

Baseline: 75.24%
System accuracy: 81.28%

Fold  4 / 10
------------

                  +-----------------+-----------------+-----------------+
                  | Target positive | Target negative | SUM             |
+-----------------+-----------------+-----------------+-----------------+
| System positive |     570  68.92% |     132  15.96% |     702  84.89% |
+-----------------+-----------------+-----------------+-----------------+
| System negative |      30   3.63% |      95  11.49% |     125  15.11% |
+-----------------+-----------------+-----------------+-----------------+
| SUM             |     600  72.55% |     227  27.45% |     827         |
+-----------------+-----------------+-----------------+-----------------+

Baseline: 72.55%
System accuracy: 80.41%

Fold  5 / 10
------------

                  +-----------------+-----------------+-----------------+
                  | Target positive | Target negative | SUM             |
+-----------------+-----------------+-----------------+-----------------+
| System positive |     564  68.20% |     114  13.78% |     678  81.98% |
+-----------------+-----------------+-----------------+-----------------+
| System negative |      50   6.05% |      99  11.97% |     149  18.02% |
+-----------------+-----------------+-----------------+-----------------+
| SUM             |     614  74.24% |     213  25.76% |     827         |
+-----------------+-----------------+-----------------+-----------------+

Baseline: 74.24%
System accuracy: 80.17%

Fold  6 / 10
------------

                  +-----------------+-----------------+-----------------+
                  | Target positive | Target negative | SUM             |
+-----------------+-----------------+-----------------+-----------------+
| System positive |     584  70.62% |     122  14.75% |     706  85.37% |
+-----------------+-----------------+-----------------+-----------------+
| System negative |      28   3.39% |      93  11.25% |     121  14.63% |
+-----------------+-----------------+-----------------+-----------------+
| SUM             |     612  74.00% |     215  26.00% |     827         |
+-----------------+-----------------+-----------------+-----------------+

Baseline: 74.00%
System accuracy: 81.86%

Fold  7 / 10
------------

                  +-----------------+-----------------+-----------------+
                  | Target positive | Target negative | SUM             |
+-----------------+-----------------+-----------------+-----------------+
| System positive |     615  74.37% |     111  13.42% |     726  87.79% |
+-----------------+-----------------+-----------------+-----------------+
| System negative |      28   3.39% |      73   8.83% |     101  12.21% |
+-----------------+-----------------+-----------------+-----------------+
| SUM             |     643  77.75% |     184  22.25% |     827         |
+-----------------+-----------------+-----------------+-----------------+

Baseline: 77.75%
System accuracy: 83.19%

Fold  8 / 10
------------

                  +-----------------+-----------------+-----------------+
                  | Target positive | Target negative | SUM             |
+-----------------+-----------------+-----------------+-----------------+
| System positive |     577  69.77% |     115  13.91% |     692  83.68% |
+-----------------+-----------------+-----------------+-----------------+
| System negative |      39   4.72% |      96  11.61% |     135  16.32% |
+-----------------+-----------------+-----------------+-----------------+
| SUM             |     616  74.49% |     211  25.51% |     827         |
+-----------------+-----------------+-----------------+-----------------+

Baseline: 74.49%
System accuracy: 81.38%

Fold  9 / 10
------------

                  +-----------------+-----------------+-----------------+
                  | Target positive | Target negative | SUM             |
+-----------------+-----------------+-----------------+-----------------+
| System positive |     581  70.25% |     115  13.91% |     696  84.16% |
+-----------------+-----------------+-----------------+-----------------+
| System negative |      49   5.93% |      82   9.92% |     131  15.84% |
+-----------------+-----------------+-----------------+-----------------+
| SUM             |     630  76.18% |     197  23.82% |     827         |
+-----------------+-----------------+-----------------+-----------------+

Baseline: 76.18%
System accuracy: 80.17%

Fold 10 / 10
------------

                  +-----------------+-----------------+-----------------+
                  | Target positive | Target negative | SUM             |
+-----------------+-----------------+-----------------+-----------------+
| System positive |     569  68.80% |     117  14.15% |     686  82.95% |
+-----------------+-----------------+-----------------+-----------------+
| System negative |      45   5.44% |      96  11.61% |     141  17.05% |
+-----------------+-----------------+-----------------+-----------------+
| SUM             |     614  74.24% |     213  25.76% |     827         |
+-----------------+-----------------+-----------------+-----------------+

Baseline: 74.24%
System accuracy: 80.41%

Summary
-------

+---------------------------+---------+----------+
| System better             |      10 |  100.00% |
+---------------------------+---------+----------+
| Baseline better           |       0 |    0.00% |
+---------------------------+---------+----------+
| Average accuracy baseline |             74.62% |
+---------------------------+--------------------+
| Average accuracy system   |             80.90% |
+---------------------------+--------------------+
</code></pre>
</body></html>
